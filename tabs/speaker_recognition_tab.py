import sys
import os
import librosa
import numpy as np
import sounddevice as sd
import wave
from PyQt5.QtWidgets import QApplication, QMainWindow, QWidget, QVBoxLayout, QTabWidget, QLabel, QPushButton, QTextEdit
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
from PyQt5.QtCore import Qt
import os

dataset_path = 'C:\\Users\\user\\PycharmProjects\\SesAnalizi\\ses_kayitlari'


class SpeakerRecognitionTab(QWidget):
    def __init__(self):
        super().__init__()
        self.init_ui()
        self.model = RandomForestClassifier()  # Modeli baÅŸlatÄ±yoruz

    def init_ui(self):
        layout = QVBoxLayout()

        # BaÅŸlÄ±k
        title = QLabel("ğŸ¤ Ses TanÄ±ma Modeli ve Metrikler")
        title.setStyleSheet("font-size: 18px; font-weight: bold; color: #1976D2;")
        layout.addWidget(title)

        # SonuÃ§ metin alanÄ±
        self.result_area = QTextEdit()
        self.result_area.setReadOnly(True)
        layout.addWidget(self.result_area)

        # Modeli eÄŸitme butonu
        train_button = QPushButton("Modeli EÄŸit ve SonuÃ§larÄ± GÃ¶ster")
        train_button.clicked.connect(self.train_model)
        layout.addWidget(train_button)

        # Ses kaydetme butonu
        record_button = QPushButton("Ses Kaydet ve Tahmin Et")
        record_button.clicked.connect(self.record_and_predict)
        layout.addWidget(record_button)

        self.setLayout(layout)

    def prepare_training_data(self):
        X = []
        y = []
        speaker_labels = {'Kisi1': 0, 'Kisi2': 1}  # KonuÅŸmacÄ± etiketleri

        for speaker, label in speaker_labels.items():
            speaker_folder = os.path.join(dataset_path, speaker)
            if os.path.exists(speaker_folder):
                for file in os.listdir(speaker_folder):
                    if file.endswith('.wav'):
                        file_path = os.path.join(speaker_folder, file)
                        try:
                            # Ses dosyasÄ±nÄ± yÃ¼kleyin ve MFCC Ã¶zelliklerini Ã§Ä±karÄ±n
                            audio, sr = librosa.load(file_path, sr=None, mono=True)
                            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)  # MFCC'yi daha tutarlÄ± Ã§Ä±karalÄ±m
                            mfcc = np.mean(mfcc.T, axis=0)  # MFCC'yi ortalama alarak sabitleyin

                            X.append(mfcc)
                            y.append(label)
                        except Exception as e:
                            print(f"Hata: {file_path} dosyasÄ±nda problem oluÅŸtu - {e}")
            else:
                print(f"{speaker_folder} dizini bulunamadÄ±!")

        return np.array(X), np.array(y)

    def train_model(self):
        try:
            X_train, y_train = self.prepare_training_data()

            # Modeli oluÅŸturun ve eÄŸitin
            self.model.fit(X_train, y_train)

            # SonuÃ§larÄ± gÃ¶sterme
            self.result_area.setText("Model eÄŸitildi baÅŸarÄ±yla!")

        except FileNotFoundError as e:
            self.result_area.setText(str(e))
        except Exception as e:
            self.result_area.setText(f"Beklenmedik bir hata oluÅŸtu: {e}")

    def record_and_predict(self):
        # Ses kaydetme iÅŸlemi
        fs = 16000  # Ses Ã¶rnekleme frekansÄ±
        duration = 3  # KayÄ±t sÃ¼resi (3 saniye)
        self.result_area.setText("Ses kaydediliyor...")

        # KaydÄ± baÅŸlat
        audio_data = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')
        sd.wait()  # KayÄ±t bitene kadar bekle

        # Ses kaydÄ±nÄ± dosyaya kaydet
        self.save_audio(audio_data, fs, "test_recording.wav")

        # Ses kaydÄ±nÄ± yÃ¼kleyip tahmin etme
        predicted_speaker = self.predict_speaker_from_file("test_recording.wav")

        # Sonucu kullanÄ±cÄ±ya gÃ¶ster
        self.result_area.setText(f"KonuÅŸmacÄ± Tahmini: {predicted_speaker}")

    def save_audio(self, audio_data, fs, filename):
        # KayÄ±t edilen ses verisini dosyaya kaydetme
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(fs)
            wf.writeframes(audio_data.tobytes())

    def predict_speaker_from_file(self, audio_file):
        # Kaydedilen ses dosyasÄ±ndan Ã¶zellik Ã§Ä±karma ve tahmin yapma
        try:
            audio, sr = librosa.load(audio_file, sr=None, mono=True)
            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)  # MFCC Ã¶zelliklerini Ã§Ä±kar
            mfcc = np.mean(mfcc.T, axis=0)  # Ã–zellik Ã§Ä±karÄ±mÄ±

            # Tahmin yap
            predicted_speaker = self.model.predict([mfcc])
            return "Kisi1" if predicted_speaker[0] == 0 else "Kisi2"
        except Exception as e:
            self.result_area.setText(f"Hata: {e}")
            return "Hata"


class VoiceAnalysisApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Ses Analizi UygulamasÄ±")
        self.setGeometry(100, 100, 1280, 720)

        # Ana widget ve layout
        main_widget = QWidget()
        self.setCentralWidget(main_widget)
        layout = QVBoxLayout(main_widget)

        # BaÅŸlÄ±k
        title = QLabel("Ses Analizi ve Duygu TanÄ±ma Sistemi")
        title.setStyleSheet("""
            QLabel {
                color: #1976D2;
                font-size: 24px;
                font-weight: bold;
                padding: 10px;
            }
        """)
        layout.addWidget(title, alignment=Qt.AlignCenter)

        # Tab widget oluÅŸturma
        tabs = QTabWidget()
        layout.addWidget(tabs)

        # TÃ¼m tablarÄ± ekleme
        tabs.addTab(SpeakerRecognitionTab(), "ğŸ‘¤ KonuÅŸmacÄ± TanÄ±ma")


# Ana fonksiyon
def main():
    app = QApplication(sys.argv)

    # Uygulama penceresini baÅŸlat
    window = VoiceAnalysisApp()
    window.show()

    sys.exit(app.exec_())

if __name__ == '__main__':
    main()
